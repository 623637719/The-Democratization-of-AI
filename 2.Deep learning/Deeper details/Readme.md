# Topics:

## [Bias and Variance]
## [Early stopping]
## [Normalisation]
## [Vanishing exploding gradients]
## [Mini Batch Gradient Descent]
## [Exponentially weighted averages]
## [Gradient Descent with Momentum]
## [RMSprop]
## [Adam]
## [Learning rate decay]
## [Coarse to fine]
## [Caviar(parallel) vs Panda(babysitting)]
